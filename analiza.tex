\section{Analiza}
\label{sec:analiza}


\subsection{Dobór metryki}
% RACZEJ TABELKA
%\textit{Do zdefiniowania metryk użyte będą skróty angielskich terminów TP, TN, FP, FN, oznaczające kolejno liczbę poprawnie zaklasyfikowanych przykładów pozytywnych, liczbę poprawnie zaklasyfikowanych przykładów negatywnych, liczbę błędnie zaklasyfikowanych przykładów negatywnych (zaklasyfikowanych jako pozytywne) i liczbę błędnie zaklasyfikowanych przykładów pozytywnych (zaklasyfikowanych jako negatywne)}

Bardzo ważnym elementem w trenowaniu algorytmów uczenia maszynowego jest dobór odpowiedniej metryki -- klasycznym złym przykładem jest używanie dokładności \angterm{accuracy} do oceniania klasyfikacji binarnej w przypadku dużego niezrównoważenia klas -- algorytm przewidujący zawsze klasę większościową może osiągnąć dużą wartość dokładności będąc jednocześnie bardzo słabym modelem.

Kilka najczęściej używanych metryk wymieniono w Tab. \ref{tab:metryki}. Używanie i porównywanie kilku miar efektywności jest często niepraktyczne dlatego dobrze jest wybrać jedną metrykę. Przy jej wyborze należy kierować się potencjalnymi zastosowaniami modelu. W tym przypadku są to analizy fizyczne, które mogą mieć różne wymagania dotyczące czystości i liczebności otrzymywanych próbek a co za tym idzie, preferować inne punkty pracy zdefiniowane jako pary liczb: wydajność poprawnej klasyfikacji dżetów \textit{b} \angterm{tagging efficiency = true positive rate = recall}, i ułamek niepoprawnie zaklasyfikowanych przypadków tła \angterm{mistagging rate = false positive rate}. 

Naturalnym wyborem wydaje się pole pod powierzchnią krzywej ROC \angterm{ROC Area Under Curve -- ROC AUC} \cite{bradley1997use}. Potencjalną przeszkodą może być zakres rozsądnych wartości prawdopodobieństwa błędnej klasyfikacji przypadków tła: dżety \textit{b} stanowią tylko kilka procent liczby wszystkich dżetów, zatem z punktu widzenia analizy dopuszczalne będą punkty pracy zapewniające wydajność identyfikacji dżetów \textit{b} ok. 10 -- 100 razy większą niż częstość niepoprawnego zaklasyfikowania przypadków tła. Oznacza to, że zdecydowana większość punktów pracy znajdujących się na krzywej ROC jest nie do zaakceptowania -- interesujące są tylko te o najniższych częstościach błędnej klasyfikacji.
%[\#REF, znaleźć liczby]
%https://books.google.pl/books?id=_FkGCwAAQBAJ&pg=
%PA133&lpg=PA133&dq=b+jets+gluon+abundance&source=bl&ots=
%rjYwb0Ux1d&sig=sw9aXh6PWRD-7EP8NGSucHFcnso&hl=pl&sa=X&ved=
%0ahUKEwiZucPzuKPcAhUFUlAKHT8ODa0Q6AEINTAB#v=onepage&q=
%b%20jets%20gluon%20abundance&f=false]

Aby ilościowo porównywać różne algorytmy wprowadzone zostaną trzy punkty pracy: o prawdopodobieństwie błędnej klasyfikacji tła równej 0.1\%, 1\% oraz 10\%.
Na Rys. \ref{fig:all-metrics-vs-bEff} przedstawione zostały zależności poszczególnych metryk od wydajności identyfikacji dżetów \textit{b} w tych trzech punktach pracy. Każdy punkt odpowiada jednemu eksperymentowi (dla dowolnego algorytmu) przeprowadzonemu w trakcie przygotowywania analizy. Daje to pogląd, na to która metryka zapewni jednocześnie wysokie wartości wydajności na identyfikację dżetów \textit{b} w wybranych punktach pracy. 
Najwyższe korelacje występują dla punktu pracy o najwyższym prawdopodobieństwie błędnej klasyfikacji tła -- jak będzie to pokazane później wyniki dla tego punktu pracy są najbardziej stabilne. Spośród analizowanych metryk najwyższe wartości współczynnika Pearsona otrzymano dla pola pod powierzchnią krzywej ROC, dosyć wysokie również dla dokładności i precyzji. Widać, że wartości czułości są najsłabiej skorelowane z wydajnością identyfikacji dżetów \textit{b} -- jest zrozumiałe, że są one dużo niższe niż dla precyzji: wartości czułości maleją gdy błędnie klasyfikowane są dżety \textit{b} stanowiące sygnał, podczas gdy wartości precyzji maleją, gdy błędnie klasyfikowane są przypadki tła. 
Z tych dwóch błędów, drugi jest bardziej kosztowny, gdyż błędna klasyfikacja nawet niewielkiej części tła znacznie pogarsza czystość otrzymywanej próbki.


\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\textwidth]{all-metrics-vs-bEff.png}
	\caption{Zależność podstawowych metryk od wydajności identyfikacji dżetów \textit{b} dla punktów pracy o prawdopodobieństwie błędnej klasyfikacji tła równej 0.1\%, 1\% oraz 10\%. Dla każdego wykresu przedstawiono współczynnik korelacji $r$ Pearsona.}
	\label{fig:all-metrics-vs-bEff}
\end{figure}

Na Rys. \ref{fig:all-metrics-vs-bEff_perc75} przedstawiono te same wykresy, ale tym razem wybrano tylko 25\% najlepszych wartości dla każdej metryki -- te punkty są bardziej znaczące, gdyż ostatecznie modele z eksperymentów dających najlepsze wyniki będą używane.
Dla tych wykresów otrzymano zdecydowaną dominację \textit{ROC AUC} -- wybór modeli dających najwyższe pole pod powierzchnią krzywej ROC zapewnia jednocześnie otrzymanie wysokich wartości wydajności identyfikacji dżetów \textit{b} dla wybranych punktów pracy.

\begin{figure}[h]
	\centering
%	\vspace{-1em}
	\includegraphics[width=0.8\textwidth]{roc_auc-vs-bEff_perc75.png} 
	
	\vspace{-1.5em}
	\includegraphics[width=0.8\textwidth]{accuracy-vs-bEff_perc75.png}
	
	\vspace{-1.5em}
	\includegraphics[width=0.8\textwidth]{precision-vs-bEff_perc75.png}
	
	\vspace{-1.5em}
	\includegraphics[width=0.8\textwidth]{recall-vs-bEff_perc75.png}
	
	\vspace{-1.2em}
	\includegraphics[width=0.8\textwidth]{F1-vs-bEff_perc75.png}
	
	\caption{Rysunek podobny do Rys. \ref{fig:all-metrics-vs-bEff}, ale przedstawione zostały tylko punkty odpowiadające eksperymentom o wartościach metryki będących w górnym kwartylu wartości danej metryki dla wszystkich eksperymentów.}
	\label{fig:all-metrics-vs-bEff_perc75}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\FloatBarrier
\subsection{Wyniki dla poszczególnych modeli}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

W następnych podrozdziałach przedstawione zostały wyniki uzyskane dla poszczególnych modeli. Jako model rozumiana jest para: algorytm (wraz z jego hiperparametrami) oraz zestaw danych użyty do jego trenowania. Oznaczenia używane w prezentacji wyników zebrane zostały w Dodatku \ref{sec:app:skroty}. 

Każdy przedstawiony wynik jest rezultatem uśrednienia pięciu powtórzeń wykonania treningu -- randomizacji podlega podział zbioru danych na dane treningowe, walidacyjne i testowe, losowa jest także inicjalizacja wag połączeń w przypadku sieci neuronowych.

Na Rys. \ref{fig:ROC_SV}, \ref{fig:ROC_constit}, \ref{fig:ROC_merged} przedstawiono odmianę krzywej ROC -- wykresy przedstawiające zależności wydajności identyfikacji dżetów \textit{b} z niepewnościami (na osi poziomej) dla danego prawdopodobieństwa błędnej klasyfikacji dżetów tła (na osi pionowej). 

Trzy krzywe na każdym wykresie odpowiadają separacji dżetów \textit{b} od dżetów: lekkich, \textit{c} oraz mieszanej próbki złożonej w 90\% z dżetów lekkich i w 10\% z dżetów powabnych.
Cztery wykresy na każdym rysunku odpowiadają trzem użytym algorytmom (sieci neuronowe typu \textit{FC} (na górze po lewej), konwolucyjne sieci neuronowe (na górze po prawej), wzmacniane drzewa decyzyjne (na dole po lewej) oraz porównanie wszystkich trzech (na dole po prawej) -- tylko średnie wartości. 

Jeśli nie zaznaczono inaczej, prezentowane wyniki dotyczą separacji dżetów \textit{b} od mieszanego tła (90\% dżetów lekkich + 10\% \textit{c})

W Tab. \ref{tab:wyniki-modeli} przedstawiono podsumowanie wyników.

\clearpage
\FloatBarrier
\subsubsection{Wyniki dla zmiennych związanych z wtórnymi wierzchołkami}

Na Rys. \ref{fig:ROC_SV} przedstawiono rezultaty uzyskane przy trenowaniu na zbiorze danych \textit{SV}. Uzyskano bardzo zbliżone wyniki dla wszystkich trzech algorytmów, sieci konwolucyjne były nieznacznie skuteczniejsze przy wydajnościach na identyfikację dżetów \textit{b} poniżej 70\% -- dla tych samych prawdopodobieństw błędnej klasyfikacji tła uzyskiwały wydajności identyfikacji lepsze o ok. 5\%.

\begin{figure}[ht]
	\centering
    \begin{subfigure}[b]{0.49\textwidth}
	\includegraphics[trim={0.5cm 0 1.5cm 1.0cm},clip,width=\textwidth]{plot_mistag_models-subbranch-SV_FC-paramset5_uncert.png}
	\caption{\textit{NN FC}}
	\end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
	\includegraphics[trim={0.5cm 0 1.5cm 1.0cm},clip,width=\textwidth]{plot_mistag_models-subbranch-SV_conv-paramset5_uncert.png}	
	\caption{\textit{NN Conv}}
	\end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
	\includegraphics[trim={0.5cm 0 1.5cm 1.0cm},clip,width=\textwidth]{plot_mistag_models-subbranch-SV_xgb-paramset1_uncert.png}
	\caption{\textit{BDT}}
	\end{subfigure}
	\begin{subfigure}[b]{0.49\textwidth}
	\includegraphics[trim={0.5cm 0 1.5cm 1.0cm},clip,width=\textwidth]{compare_SV.png}
	\caption{porównanie}
	\end{subfigure}	
	
	\caption{Zależności wydajności identyfikacji dżetów \textit{b} od prawdopodobieństwa błędnej klasyfikacji dżetów tła dla poszczególnych algorytmów oraz ich porównanie. Algorytmy wytrenowane na zmiennych \textit{SV}.}
	\label{fig:ROC_SV}
\end{figure}



\clearpage
\FloatBarrier
\subsubsection{Wyniki dla zmiennych związanych z cząstkami tworzącymi dżet}

Na Rys. \ref{fig:ROC_constit} przedstawiono rezultaty uzyskane przy trenowaniu na zbiorze danych \textit{constit}. Wyniki dla \textit{BDT} oraz \textit{Conv} są niemal identyczne, dla \textit{BDT} trochę lepsze niż w przypadku zestawu danych \textit{SV}, natomiast te uzyskane dla sieci neuronowych typu \textit{FC} są znacznie gorsze. Stosunkowo najmniejsze różnice pomiędzy zestawami danych \textit{SV} i \textit{constit} dla algorytmu \textit{FC} otrzymano w przypadku separacji dżetów \textit{b} od \textit{c}.

\begin{figure}[ht]
	\centering
	
    \begin{subfigure}[b]{0.49\textwidth}
	\includegraphics[trim={0.5cm 0 1.5cm 1.0cm},clip,width=\textwidth]{plot_mistag_models-subbranch-constit_FC-paramset1_uncert.png}
	\caption{\textit{NN FC}}
	\end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
	\includegraphics[trim={0.5cm 0 1.5cm 1.0cm},clip,width=\textwidth]{plot_mistag_models-subbranch-constit_conv-paramset5_uncert.png}	
	\caption{\textit{NN Conv}}
	\end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
	\includegraphics[trim={0.5cm 0 1.5cm 1.0cm},clip,width=\textwidth]{plot_mistag_models-subbranch-constit_xgb-paramset1_uncert.png}
	\caption{\textit{BDT}}
	\end{subfigure}
	\begin{subfigure}[b]{0.49\textwidth}
	\includegraphics[trim={0.5cm 0 1.5cm 1.0cm},clip,width=\textwidth]{compare_constit.png}
	\caption{porównanie}
	\end{subfigure}
	
	\caption{Zależności wydajności identyfikacji dżetów \textit{b} od prawdopodobieństwa błędnej klasyfikacji dżetów tła dla poszczególnych algorytmów oraz ich porównanie. Algorytmy wytrenowane na zmiennych \textit{constit}.}
	\label{fig:ROC_constit}
\end{figure}

\clearpage
\FloatBarrier
\subsubsection{Wyniki dla wszystkich zmiennych}

Na Rys. \ref{fig:ROC_merged} przedstawiono rezultaty uzyskane przy trenowaniu na zbiorze danych \textit{merged}.
Ponownie krzywe ROC wzmacnianych drzew decyzyjnych i sieci konwolucyjnych prawie się nie różnią, natomiast dla sieci w pełni połączonych krzywa jest przesunięta o ok. 0.1 \#\#\# w stronę niższych wydajności.

W porównaniu do poprzednich zbiorów danych wszystkie algorytmy poprawiły swoje predykcje, najmniej \textit{FC}, którego zdolności separacyjne są prawie takie same jak w przypadku \textit{SV} (trochę lepsza separacja \textit{b} od \textit{c}).

\begin{figure}[ht]
	\centering
	
    \begin{subfigure}[b]{0.49\textwidth}
	\includegraphics[trim={0.5cm 0 1.5cm 1.0cm},clip,width=\textwidth]{plot_mistag_models-merged_FC-paramset105_uncert.png}
	\caption{\textit{NN FC}}
	\end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
	\includegraphics[trim={0.5cm 0 1.5cm 1.0cm},clip,width=\textwidth]{plot_mistag_models-merged_conv-paramset104_uncert.png}	
	\caption{\textit{NN Conv}}
	\end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
	\includegraphics[trim={0.5cm 0 1.5cm 1.0cm},clip,width=\textwidth]{plot_mistag_models-merged_xgb-paramset1_uncert.png}
	\caption{\textit{BDT}}
	\end{subfigure}
	\begin{subfigure}[b]{0.49\textwidth}
	\includegraphics[trim={0.5cm 0 1.5cm 1.0cm},clip,width=\textwidth]{compare_merged.png}
	\caption{porównanie}
	\end{subfigure}
	
	\caption{Zależności wydajności identyfikacji dżetów \textit{b} od prawdopodobieństwa błędnej klasyfikacji dżetów tła dla poszczególnych algorytmów oraz ich porównanie. Algorytmy wytrenowane na zmiennych \textit{merged}.}
	\label{fig:ROC_merged}
\end{figure}

\FloatBarrier
\subsubsection{Podsumowanie}
\label{subsubsec:wyniki-modeli-podsum}

Uzyskane wartości \textit{ROC AUC} oraz wydajności identyfikacji dżetów \textit{b} dla trzech punktów pracy zebrano w Tab. \ref{tab:wyniki-modeli}.

Tak jak było to widać na Rys. \ref{fig:all-metrics-vs-bEff_perc75}, z \textit{ROC AUC} najbardziej skorelowane są wydajności dla punktu pracy o najwyższych wydajnościach. Wynika to z faktu, że pierwsze dwa punkty pracy leżą na samym początku krzywej ROC (dają niewielki wkład do pola pod krzywą).

Algorytm wytrenowany na połączonym zbiorze danych daje trochę lepsze wyniki niż trenowany na zbiorach \textit{SV} i \textit{constit}, co jest oczywiście oczekiwane. Można było natomiast spodziewać się większej poprawy, co pokazuje, że predykcje algorytmów trenowanych na \textit{SV} oraz \textit{constit} muszą być skorelowane (przy założeniu, że model trenowany na dwóch połączonych zbiorach danych daje wyniki niegorsze niż trywialne połączenie dwóch modeli trenowanych na osobnych zbiorach danych).

W każdym przypadku najgorsze wyniki uzyskano dla sieci w pełni połączonych.
Z tabeli wynika, że duże znaczenie mają zarówno użyty algorytm jak i zestaw danych.
Wysokie podobieństwo wyników uzyskiwanych dla \textit{BDT} oraz \textit{Conv} pozwala przypuszczać, że uzyskiwane przez nie poziom błędu jest zbliżony do minimum osiągalnego przy tych zestawach danych (błędu \textit{Bayesowskiego}).



\begin{table}[ht]
\centering
\begin{tabular}{lcp{1.8cm}p{1.8cm}p{1.8cm}}
\toprule
                      &                   & \multicolumn{3}{c}{wydajność identyfikacji dżetów \textit{b} [\%]}    \\
model                 & \textit{ROC AUC}  & \multicolumn{3}{c}{dla prawd. błędnej klas. tła równej} \\
                      & \hspace{9em}                  & \hspace{0.5em} 0.1\%             & \hspace{0.5em} 1\%              & \hspace{0.5em} 10\%             \\
\midrule                      
\textit{SV-FC}        & 0.901 $\pm$ 0.003 & 15 $\pm$ 3        & 39 $\pm$ 2       & 73.7 $\pm$ 0.6       \\
\textit{SV-Conv}      & 0.912 $\pm$ 0.001 & 18 $\pm$ 3        & 45 $\pm$ 2       & 76.4 $\pm$ 0.8       \\
\vspace{5pt}
\textit{SV-BDT}       & 0.909 $\pm$ 0.002 & 13 $\pm$ 4        & 38 $\pm$ 1       & 76.3 $\pm$ 0.6       \\
\textit{constit-FC}   & 0.839 $\pm$ 0.005 & \hspace{0.5em}2 $\pm$ 1         & 15 $\pm$ 2       & 58.6 $\pm$ 1.5       \\
\textit{constit-Conv} & 0.911 $\pm$ 0.002 & 20 $\pm$ 2        & 46 $\pm$ 3       & 77.8 $\pm$ 0.6       \\
\vspace{5pt}
\textit{constit-BDT}  & 0.918 $\pm$ 0.001 & 20 $\pm$ 3        & 48 $\pm$ 3       & 79.4 $\pm$ 0.7       \\
\textit{merged-FC}    & 0.903 $\pm$ 0.002 & 13 $\pm$ 6        & 41 $\pm$ 2       & 74.2 $\pm$ 0.3       \\
\textit{merged-Conv}  & 0.925 $\pm$ 0.003 & 18 $\pm$ 2        & 48 $\pm$ 3       & 81.3 $\pm$ 0.4       \\
\textit{merged-BDT}   & 0.925 $\pm$ 0.001 & 16 $\pm$ 5        & 51 $\pm$ 1       & 81.4 $\pm$ 0.4		\\
\bottomrule  
\end{tabular}
\caption{Tabela podsumowująca wyniki uzyskane przez poszczególne modele.}
\label{tab:wyniki-modeli}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\FloatBarrier
\subsection{Korelacje predykcji modeli}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Na Rys. \ref{fig:models_corr} przedstawiono korelacje pomiędzy poszczególnymi modelami. Korelacje obliczano pomiędzy wynikami zwracanym bezpośrednio przez algorytmy (liczba rzeczywista $\in [0,1]$), nie na podstawie odpowiadających im klas ($\{0,1\}$).

Pierwszy wniosek płynący z wykresu korelacji to fakt, że wszystkie modele są ze sobą silnie skorelowane. Tłumaczy to niewielki zysk płynący z połączenia zestawów danych \textit{SV} i \textit{constit} co wspomniano w podrozdziale \ref{subsubsec:wyniki-modeli-podsum}.

Najmniejszymi korelacjami z innymi wyróżnia się model \textit{constit-FC}, który dawał zdecydowanie najsłabsze wyniki.

Widać wyraźny wzrost korelacji w przypadku modeli trenowanych na tych samych zbiorach danych (szczególnie dla modeli trenowanych na zmiennych związanych z wtórnymi wierzchołkami). 
Modele trenowane na połączonym zbiorze danych są nieco silniej skorelowane z modelami \textit{SV-X} niż \textit{constit-X}
Nie obserwuje się natomiast istotnie większych korelacji między modelami wykorzystującymi ten sam algorytm.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{models_correlation.png}
	\caption{Średnie współczynniki korelacji Pearsona pomiędzy predykcjami poszczególnych modeli. Odchylenia standardowe wynosiły 0.001 -- 0.009.}
	\label{fig:models_corr}
\end{figure}

\FloatBarrier
\subsection{Analiza istotności cech}



\newlength{\everyNthRowSpace}
\setlength{\everyNthRowSpace}{10pt}


\begin{table}
\centering
\begin{tabular}{lrrr}
\toprule
{} & \multicolumn{3}{c}{trening osobno} \\
{} & \textit{weight} & \textit{total\_gain} & \textit{total\_cover} \\
\midrule
$L_{xy}$ - SV0          &         2.76 &            13.37 &              4.68 \\
$L_{xy}$ - SV2          &         1.88 &             9.83 &              3.80 \\
$L_{xy}$ - SV3          &         1.66 &             7.68 &              3.51 \\
$L_{xy}$ - SV1          &         1.34 &             6.79 &              2.84 \\
\vspace{\everyNthRowSpace}
$L_{xy}$ - SV5          &         0.77 &             3.79 &              1.78 \\
$L_{xy}$ - SV4          &         1.03 &             2.79 &              2.06 \\
$\chi^2/Ndf$ - SV0      &         3.30 &             2.30 &              2.56 \\
$L_{xy}$ - SV6          &         0.96 &             2.21 &              1.75 \\
$L_{xy}$ - SV8          &         0.96 &             2.14 &              1.81 \\
\vspace{\everyNthRowSpace}
$L_{xy}$ - SV7          &         0.89 &             1.99 &              1.59 \\
$N_{SV}$                &         0.73 &             1.73 &              1.33 \\
$\sigma_{vertex}$ - SV0 &         2.70 &             1.40 &              2.08 \\
$\sigma_{Lxy}$ - SV9    &         0.91 &             1.36 &              1.38 \\
$\chi^2/Ndf$ - SV3      &         1.91 &             1.33 &              2.14 \\
%\vspace{\everyNthRowSpace}
$M_{inv}$ - SV9         &         0.77 &             1.31 &              1.24 \\

%$\chi^2/Ndf$ - SV1      &         1.83 &             1.25 &              2.00 \\
%$\sigma_{Lxy}$ - SV0    &         2.87 &             1.20 &              1.85 \\
%$\sigma_{Lxy}$ - SV1    &         1.77 &             1.08 &              1.56 \\
%$\chi^2/Ndf$ - SV9      &         0.78 &             1.00 &              1.12 \\
%$\chi^2/Ndf$ - SV2      &         1.69 &             0.99 &              1.73 \\
\midrule
%\end{tabular}
%
%\begin{tabular}{lrrr}
%\toprule
%{} &  weight\_mean &  total\_gain\_mean &  total\_cover\_mean \\
%\midrule
$IP_{D}$ - C0 &         2.73 &            19.29 &              9.68 \\
$IP_{D}$ - C1 &         2.76 &            15.06 &              8.74 \\
$IP_{D}$ - C2 &         3.39 &            11.37 &              8.69 \\
$IP_{D}$ - C3 &         2.84 &             6.56 &              6.16 \\
\vspace{\everyNthRowSpace}
$IP_{Z}$ - C0 &         3.01 &             5.26 &              5.86 \\
$IP_{D}$ - C4 &         3.02 &             3.90 &              5.37 \\
$IP_{Z}$ - C1 &         2.50 &             3.44 &              4.63 \\
$IP_{Z}$ - C2 &         2.29 &             2.28 &              3.55 \\
$IP_{D}$ - C5 &         1.95 &             1.67 &              3.15 \\
\vspace{\everyNthRowSpace}
$IP_{Z}$ - C3 &         2.14 &             1.50 &              2.65 \\
$IP_{D}$ - C6 &         2.07 &             1.33 &              2.96 \\
$IP_{Z}$ - C4 &         1.95 &             1.10 &              2.16 \\
$p_{T}$ - C0  &         2.22 &             1.00 &              1.79 \\
$p_{T}$ - C2  &         2.14 &             0.98 &              2.04 \\
%\vspace{\everyNthRowSpace}
$\phi$ - C0   &         2.31 &             0.98 &              1.27 \\
%$\phi$ - C4   &         2.38 &             0.94 &              0.86 \\
%$p_{T}$ - C3  &         1.71 &             0.89 &              1.78 \\
%$p_{T}$ - C1  &         2.00 &             0.86 &              1.66 \\
%$\phi$ - C3   &         2.09 &             0.86 &              0.73 \\
%$\phi$ - C2   &         2.00 &             0.85 &              0.84 \\
\bottomrule
\end{tabular}
\caption{Tabela zawierająca wartości miar istotności 15 najważniejszych (wg \textit{total\_gain}) cech, osobno dla zmiennych związanych z wtórnymi wierzchołkami (górna połowa) oraz z cząstkami składowymi (dolna połowa).}
\label{tab:feat_imp_most_sv_constit}
\end{table}



%\begin{table}
%\centering
%\begin{tabular}{lrrr}
%\toprule
%{} & \multicolumn{3}{c}{trening razem} \\
%{} & \textit{weight} & \textit{total\_gain} & \textit{total\_cover} \\
%\midrule
%$L_{xy}$ - SV0                     &         1.40 &             7.43 &              3.27 \\
%$L_{xy}$ - SV3                     &         0.70 &             3.66 &              1.62 \\
%$IP_{D}$ - C0                      &         2.03 &             3.43 &              3.70 \\
%$L_{xy}$ - SV1                     &         0.70 &             2.72 &              1.28 \\
%\vspace{\everyNthRowSpace}
%$IP_{D}$ - C1                      &         1.84 &             2.56 &              3.18 \\
%$L_{xy}$ - SV2                     &         0.72 &             2.56 &              1.52 \\
%$IP_{Z}$ - C0                      &         1.64 &             1.56 &              1.79 \\
%$IP_{D}$ - C2                      &         1.56 &             1.55 &              2.19 \\
%$IP_{Z}$ - C1                      &         1.56 &             1.24 &              1.46 \\
%\vspace{\everyNthRowSpace}
%$p_{T,\;jet}$               	   &         1.23 &             1.19 &              1.86 \\
%$\chi^2/Ndf$ - SV0                 &         1.07 &             1.13 &              1.38 \\
%$IP_{D}$ - C3                      &         1.32 &             1.11 &              1.62 \\
%$\sigma_{vertex}$ - SV0            &         1.04 &             1.11 &              1.64 \\
%$IP_{Z}$ - C2                      &         1.39 &             1.04 &              1.12 \\
%\vspace{\everyNthRowSpace}
%$\eta$ - C1                        &         1.33 &             0.98 &              1.21 \\
%$IP_{D}$ - C4                      &         1.18 &             0.98 &              1.49 \\
%$\sigma_{Lxy}$ - SV0               &         0.90 &             0.97 &              0.78 \\
%$\rho_{\;bckg}$ 				   &         1.42 &             0.97 &              1.04 \\
%$\phi$ - C0                        &         1.30 &             0.94 &              1.04 \\
%\vspace{\everyNthRowSpace}
%$p_{T}$ - C0                       &         1.21 &             0.93 &              1.07 \\
%$A_{jet}$              			   &         1.33 &             0.93 &              1.17 \\
%$\eta$ - C0                        &         1.27 &             0.90 &              1.08 \\
%$M_{inv}$ - SV0                    &         1.06 &             0.90 &              0.85 \\
%$\phi$ - C1                        &         1.30 &             0.89 &              0.83 \\
%%\vspace{\everyNthRowSpace}
%$\eta$ - C2                        &         1.32 &             0.87 &              0.80 \\
%%UNKNOWN FEATURE-fVertexX           &         1.31 &             0.86 &              0.97 \\
%%$p_{T}$ - C1                       &         1.14 &             0.85 &              0.98 \\
%%$\eta$ - C3                        &         1.28 &             0.85 &              0.86 \\
%%$\sigma_{Lxy}$ - SV2               &         0.63 &             0.84 &              0.79 \\
%%UNKNOWN FEATURE-fVertexY           &         1.31 &             0.84 &              0.81 \\
%\bottomrule
%\end{tabular}
%\caption{tab2}
%\label{tab:feat_imp_most_merged}
%\end{table}




\begin{table}
\centering
\begin{tabular}{l|rrr|rrr}
\toprule
{} & \multicolumn{3}{c|}{trening osobno} & \multicolumn{3}{c}{trening razem} \\
%\midrule
{} & \textit{weight} & \textit{total\_gain} & \textit{total\_cover} & \textit{weight} &   \textit{total\_gain} &  \textit{total\_cover} \\
\midrule
$L_{xy}$              &     17.2 &         54.5 &          28.9 &    6.9 &       21.1 &        12.9 \\
$\sigma_{Lxy}$         &     19.4 &         13.1 &          18.1 &    7.2 &        8.5 &         7.9 \\
$M_{inv}$             &     18.3 &          8.0 &          14.1 &    7.6 &        6.8 &         6.8 \\
$\sigma_{vertex}$       &     17.0 &          8.2 &          14.2 &    6.6 &        6.0 &         6.9 \\
$\chi^2/Ndf$             &     19.3 &         12.8 &          19.5 &    7.1 &        6.6 &         7.9 \\
\cline{1-4}
$IP_D$ &     22.4 &         60.6 &          47.5 &   11.3 &       12.3 &        16.1 \\
$IP_Z$ &     18.3 &         16.1 &          23.3 &    9.9 &        7.7 &         9.3 \\
$p_T$               &     14.0 &          7.1 &          14.1 &    7.0 &        5.7 &         6.2 \\
$\phi$              &     23.2 &          8.7 &           8.2 &   12.4 &        8.4 &         8.2 \\
$\eta$              &     21.7 &          7.3 &           6.4 &   13.0 &        8.8 &         8.9 \\
\bottomrule
\end{tabular}
\caption{Tabela zawierająca wartości miar istotności cech, posumowane według rodzaju zmiennej (sumy po wszystkich wtórnych wierzchołkach / wszystkich cząstkach). 
Wartości w lewej części odpowiadają wynikom przedstawionym na Rys. \ref{fig:ROC_SV} c) oraz \ref{fig:ROC_constit} c) natomiast z prawej -- na Rys. \ref{fig:ROC_merged} c).
Kolumny nie sumują się do 100, ze względu na pominięcie zmiennych występujących jeden raz dla każdego dżetu, tj. $N_{SV}$ i  $N_{Constit}$ oraz zmiennych na poziomie dżetu.}
\label{tab:feat_imp_by_name}
\end{table}



XXX Co warte podkreślenia: spora stabilność -- odchylenia std sporadycznie ponad 10\%, za wyjątkiem zmiennych SV przy treningu tylko na SV: wtedy 10-20\% a nawet więcej

feat imp: frequency dla binarnych

%Niezwykle ważny element, 
%w trakcie prób możliwe jest czasem analizowanie wiekszej liczby metryk jednak jest to niepraktyczne gdy eksperymentow jest wiele i trzeba porownywac kilka liczb.
% Interesujace z punktu widzenia fizyki punkty pracy - obszar krzywej ROC, hipotetyczna krzywa ROC o duzym polu i malej przydatnosci: 
%
%rozne analizy = rozne punkty pracy

%/\
%|
%1   _______________
%|  |
%|  | 
%|  |
%|  |
%|  |    AUC=0.99
%| /
%|/________________1_____\
%0                       /





%
%
%\subsection*{Single var tager}
%\subsection*{Results for SV, Constit, Merged}
%\subsection*{pT dependence of performance}
%\subsection*{Corr of algos pred}
%\subsection*{Feature imp \& partial dependence}
%
% TODO
% plot: ROC - all models - lt = features(SV/constit/merged), color=algo(BDT/FC/Conv)
% tab_most - zdecydowanie osobno trening_osobno i trening_razem
